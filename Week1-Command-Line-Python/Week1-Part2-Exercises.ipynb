{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd0d302d-cb1a-48a5-8524-e3ed19036fc4",
   "metadata": {},
   "source": [
    "# Week 1 — Part 2 Exercises — Text Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b5a547-1714-4570-aaa7-6a0187b55a46",
   "metadata": {},
   "source": [
    "*Make sure that you work on these exercises and then submit a screenshot of your work to the appropriate assignment page in Canvas.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f44ee54-4248-45d6-bd93-e213c5e3c541",
   "metadata": {},
   "source": [
    "## ✨Group Work Madlibs✨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e555e07-0955-4e8e-bddd-a3262fd186b4",
   "metadata": {},
   "source": [
    "In the first exercise, you're going to ask your partner(s) a few biographical questions about themselves and then put their answers into the correct variables with the correct data types.\n",
    "\n",
    "Here's an example (with actual responses replaced by None):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3fbb7bb-c391-4965-95c6-e07c76f2c970",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = None  #string\n",
    "age = None            #integer\n",
    "place = None     #string\n",
    "favorite_food = None #string \n",
    "dog_years_age = None    #float \n",
    "student_boolean = None        #boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58be2d1c-1ff9-4584-b6b1-eaf41583dce5",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✨This is...Prof. Walsh!✨\n",
      "\n",
      "Prof. Walsh likes tacos and once lived in Chicago.\n",
      "Prof. Walsh is 1000 years old, which is 7500.0 in dog years.\n",
      "The statement 'Prof. Walsh is a student' is False.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'✨This is...{name}!✨')\n",
    "\n",
    "print(f\"\"\"\n",
    "{name} likes {favorite_food} and once lived in {place}.\n",
    "{name} is {age} years old, which is {dog_years_age} in dog years.\n",
    "The statement '{name} is a student' is {student_boolean}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9968b219-baf5-4dea-8237-ca3a76a5093e",
   "metadata": {},
   "source": [
    "**1.** Ask your partner a few questions and then fill in the variables below accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a91ad60-aa04-41b7-a969-a1de9802e9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = None  #string\n",
    "age = None            #integer\n",
    "place = None     #string\n",
    "favorite_food = None #string \n",
    "dog_years_age = None    #float * 7.5\n",
    "student_boolean = None        #boolean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c777a14b-daae-4c81-8db6-848bd7461da3",
   "metadata": {},
   "source": [
    "**2.** Now print the introduction below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc03d659-d27a-4b10-945a-f9b46d957186",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'✨This is...{name}!✨')\n",
    "\n",
    "print(f\"\"\"{name} likes {favorite_food} and once lived in {place}.\n",
    "{name} is {age} years old, which is {dog_years_age} in dog years.\n",
    "The statement \"{name} is a student\" is {student_boolean}.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152bc46b-81a7-4b25-9820-74e1c0257710",
   "metadata": {},
   "source": [
    "## Changes Variables and Values in a Real Script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6368c29-72a2-431c-b984-34b62534f4a5",
   "metadata": {},
   "source": [
    "Let's explore how variables are used in a real Python script. The code below will calculate the most frequent words in a text file.\n",
    "\n",
    "**3.** Experiment with altering the code below below in three ways:\n",
    "- First, choose different stopwords to exclude or include, and then see how your results change.\n",
    "- Second, choose a different text from our `texts` directory and calculate the most frequent words for that text.\n",
    "- Third, choose a different number of frequent words to to print out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc837360-1fb5-4065-998f-8616755ab420",
   "metadata": {},
   "source": [
    "To see a list of the other text filepaths that you can choose from, you can use the `ls` command like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbdd516a-a4f1-40ee-8c23-01810a703e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[30m\u001b[43mAfrican American Literature Text Corpus\u001b[m\u001b[m\n",
      "\u001b[31mAfrican-American-Literature-1853-1923.zip\u001b[m\u001b[m\n",
      "\u001b[31mAlice-in-Wonderland_Lewis-Carroll.txt\u001b[m\u001b[m\n",
      "\u001b[31mBlazing-World_Margaret_Cavendish.txt\u001b[m\u001b[m\n",
      "\u001b[30m\u001b[43mColonial South Asian Literature, 1850-1923\u001b[m\u001b[m\n",
      "\u001b[31mColonial-South-Asian-Literature-1850-1923.zip\u001b[m\u001b[m\n",
      "\u001b[31mDiary-of-a-Plague-Year_Daniel-Defoe.txt\u001b[m\u001b[m\n",
      "\u001b[31mDracula_Bram-Stoker.txt\u001b[m\u001b[m\n",
      "\u001b[31mFrankenstein_Mary-Shelley.txt\u001b[m\u001b[m\n",
      "\u001b[31mGrimms-Fairy-Tales.txt\u001b[m\u001b[m\n",
      "Grimms-Little-Red-Cap.txt\n",
      "Lady-With-a-Dog_Anton-Chekov-UTF8-Method1.txt\n",
      "Lady-With-a-Dog_Anton-Chekov-UTF8-Method2.txt\n",
      "\u001b[31mLady-With-a-Dog_Anton-Chekov-UTF8.txt\u001b[m\u001b[m\n",
      "\u001b[31mLady-With-a-Dog_Chekov-KOI8R.txt\u001b[m\u001b[m\n",
      "\u001b[31mLittle-Women_Louisa-May-Alcott.txt\u001b[m\u001b[m\n",
      "\u001b[30m\u001b[43mLost-in-the-City-HTRC-Extracted-Features\u001b[m\u001b[m\n",
      "\u001b[31mLost-in-the-City-HTRC-Extracted-Features.zip\u001b[m\u001b[m\n",
      "\u001b[31mMoby-Dick_Herman-Melville.txt\u001b[m\u001b[m\n",
      "\u001b[31mPride-and-Prejudice_Jane-Austen.txt\u001b[m\u001b[m\n",
      "\u001b[31mStory-of-My-Life_Helen-Keller.txt\u001b[m\u001b[m\n",
      "\u001b[31mThe-Autobiography-of-Benjamin-Franklin.txt\u001b[m\u001b[m\n",
      "\u001b[31mThe-Bible.txt\u001b[m\u001b[m\n",
      "\u001b[31mThe-Legends-and-Myths-of-Hawaii_David-Kalakaua.txt\u001b[m\u001b[m\n",
      "The-Metamorphosis_Franz-Kafka-Intro.txt\n",
      "\u001b[31mThe-Metamorphosis_Franz-Kafka.txt\u001b[m\u001b[m\n",
      "\u001b[31mThe-Souls-of-Black-Folk_W-E-B-Du-Bois.txt\u001b[m\u001b[m\n",
      "\u001b[31mThe-Trial_Franz-Kafka.txt\u001b[m\u001b[m\n",
      "\u001b[31mThe-Yellow-Wallpaper_Charlotte-Perkins-Gilman.txt\u001b[m\u001b[m\n",
      "\u001b[31mWuthering-Heights-Emily-Bronte.txt\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls ../../texts/literature/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e70f08a-8311-4755-896a-d863523f1dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mAdele-21.txt\u001b[m\u001b[m\n",
      "\u001b[31mBeyonce-Lemonade.txt\u001b[m\u001b[m\n",
      "\u001b[31mCarly-Rae-Jepsen-Emotion.txt\u001b[m\u001b[m\n",
      "\u001b[31mDrake-Take-Care.txt\u001b[m\u001b[m\n",
      "\u001b[31mHamilton-Musical.txt\u001b[m\u001b[m\n",
      "\u001b[31mHarry-Styles-Fine-Line.txt\u001b[m\u001b[m\n",
      "\u001b[31mKendrick-Lamar-To-Pimp-a-Butterfly.txt\u001b[m\u001b[m\n",
      "\u001b[31mLin-Manuel-Miranda-In-the-Heights.txt\u001b[m\u001b[m\n",
      "\u001b[31mLizzo-Cuz-I-Love-You.txt\u001b[m\u001b[m\n",
      "\u001b[31mMac-Miller-Circles.txt\u001b[m\u001b[m\n",
      "\u001b[31mMitski-Puberty-2.txt\u001b[m\u001b[m\n",
      "\u001b[31mTaylor-Swift-Red.txt\u001b[m\u001b[m\n",
      "\u001b[31mThe-Beatles-Sgt-Peppers-Lonely-Hearts-Club-Band.txt\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls ../../texts/music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6f432d-c261-4f0e-8bed-eb748efeb2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries and Modules\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Define Functions\n",
    "\n",
    "def split_into_words(any_chunk_of_text):\n",
    "    lowercase_text = any_chunk_of_text.lower()\n",
    "    split_words = re.split(\"\\W+\", lowercase_text)\n",
    "    return split_words\n",
    "\n",
    "# Define Filepaths and Assign Variables\n",
    "\n",
    "filepath_of_text = \"story-of-an-hour.txt\"\n",
    "\n",
    "# Define number of words to return\n",
    "\n",
    "number_of_desired_words = 40\n",
    "\n",
    "# Define stopwords\n",
    "\n",
    "stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
    "'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    " 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    " 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
    " 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    " 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
    " 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    " 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
    " 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    " 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    " 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
    " 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 've', 'll', 'amp']\n",
    "\n",
    "# Read in File\n",
    "\n",
    "full_text = open(filepath_of_text, encoding=\"utf-8\").read()\n",
    "\n",
    "# Manipulate and Analyze File\n",
    "\n",
    "all_the_words = split_into_words(full_text)\n",
    "meaningful_words = [word for word in all_the_words if word not in stopwords]\n",
    "meaningful_words_tally = Counter(meaningful_words)\n",
    "most_frequent_meaningful_words = meaningful_words_tally.most_common(number_of_desired_words)\n",
    "\n",
    "# Output Results\n",
    "\n",
    "most_frequent_meaningful_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daad2fcb-ab04-4566-8f12-6263458c10c9",
   "metadata": {},
   "source": [
    "## What is an interesting interpretation or argument you could make from this analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2943588a-a0b2-4dac-854e-cae870b3fe7a",
   "metadata": {},
   "source": [
    "Put your answer on Canvas: https://canvas.uw.edu/courses/1631973/assignments/8271693"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
