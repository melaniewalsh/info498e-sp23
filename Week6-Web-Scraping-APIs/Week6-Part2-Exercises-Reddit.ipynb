{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Data Collection and Analysis with PRAW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Reddit developer app and get access tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/reddit-archive/reddit/wiki/OAuth2-Quick-Start-Example#first-steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and Load PRAW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use PRAW, we first need to install it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting praw\n",
      "  Downloading praw-7.7.0-py3-none-any.whl (189 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m189.4/189.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting update-checker>=0.18\n",
      "  Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
      "Collecting prawcore<3,>=2.1\n",
      "  Downloading prawcore-2.3.0-py3-none-any.whl (16 kB)\n",
      "Collecting websocket-client>=0.54.0\n",
      "  Using cached websocket_client-1.5.1-py3-none-any.whl (55 kB)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from prawcore<3,>=2.1->praw) (2.27.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (1.26.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2020.12.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.10)\n",
      "Installing collected packages: websocket-client, update-checker, prawcore, praw\n",
      "Successfully installed praw-7.7.0 prawcore-2.3.0 update-checker-0.18.0 websocket-client-1.5.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install praw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will import pandas for eventually working with the collected data, and we will change pandas default display setting to make our DataFrame columns wider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 500)\n",
    "pd.set_option('max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will import praw and initialize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"my client id\", # Put in your client id\n",
    "    client_secret=\"my client secret\", # Put in your client secret\n",
    "    user_agent=\"my-user-agent\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Reddit posts by subreddit ‚Äî top, hot, recent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`reddit.subreddit(SUBREDDIT_NAME).top(limit=10)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for submission in reddit.subreddit(\"udub\").top(limit=10):\n",
    "    print(submission.title, \"-\", submission.author, \"\\n---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Reddit posts by subreddit ‚Äî keyword search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uw_submissions = reddit.subreddit(\"udub\")\n",
    "for submission in uw_submissions.search(\"ChatGPT\", limit=100):\n",
    "    print (submission.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Come up with your own question!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Big question:\n",
    "\n",
    "Achievable question:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now collect your own data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick at least **5 metadata categories** to collect about at least **300 submissions** from a subreddit. To find out which metadata categories exist and how to access them, you need to read the PRAW documentation below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subreddit attributes: https://praw.readthedocs.io/en/stable/code_overview/models/subreddit.html\n",
    "\n",
    "Submission attributes: https://praw.readthedocs.io/en/stable/code_overview/models/submission.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dicts_to_df = []\n",
    "\n",
    "for submission in reddit.subreddit(\"udub\").top(limit=10):\n",
    "    \n",
    "    # Get author\n",
    "    author = submission.author\n",
    "    \n",
    "    # Get title\n",
    "    title = submission.title\n",
    "    \n",
    "    # list of dictionaries for turning into a DataFrame\n",
    "    dicts_to_df.append({'author': author,\n",
    "                     'title': title})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blue book vending locations?\n",
      "Where to get a ‚Äúblue book‚Äù?\n",
      "Does anyone wanna buy my PC?\n",
      "Anyone happen to find a lost wallet last night? I think it‚Äôs technically a card holder but it‚Äôs dark blue\n",
      "Evolution of the UW huskies sports logo\n",
      "Is it normal to get a grader gig?\n",
      "Anyone find a lost wallet?\n",
      "Founder of Blue Sky Church - a church in Bellevue, arrested for aggravated criminal sodomy against a minor\n",
      "Bus Etiquette for yall who need a reminder\n",
      "Lost Airpods (2nd generation)\n",
      "Cozy places to read\n",
      "Any Aero & Astro students?\n",
      "How would one go about finding the chair or a similar chair to the light blue chairs by the life sciences cafe.\n",
      "Usps blue box on or near campus?\n",
      "Lost Keys\n",
      "Blue Five Star notebook left in old CS building 5th floor\n",
      "Upcoming Nook show\n",
      "Missing Cat\n",
      "Why does the fountain water look so blue?\n",
      "Red Square - Navy blue edition\n",
      "Urgent care for health\n",
      "Help with MATH124?\n",
      "volunteer and get FREE admission to home games??? ü§©\n",
      "District Market out of Red Bulls\n",
      "Roses are red, violets are blue, HFS reviewer where are you???\n",
      "RIP the blue Nissan Sentra that left it's sun roof cracked in E18.\n",
      "PSA: Scantrons/blue book location\n",
      "A song relevant to every UW student made by some legendary alum: Blue Scholars - The Ave\n",
      "Free MATH 126/324 textbook\n",
      "Food hygiene safety in Local Point\n",
      "Lost blue/red hat with giant \"A\" on it; anyone seen it?\n",
      "Sunset. Pink + Blue\n",
      "Anybody currently using a meal subscription service like Blue Apron or Hello Fresh?\n",
      "Cherry Blossom Dream\n",
      "Guide to getting a SWE job without a CS degree\n",
      "What to do if I want to work at NASA,Blue Origin, or etc.?\n",
      "Followed Down Ave\n",
      "Reccs for great, not-too-pricy hair colorist?\n",
      "What would you do?\n",
      "lost pants ü§†\n",
      "I love HFS and everything they do for us. Without them I would feel trapped on campus. Not knowing if I should order chicken strips or 5 day old blue c sushi. Thank you so much HFS\n",
      "I feel so represented, thanks Seattle Kraken\n",
      "Is there any club or something for rock or blues musicians?\n",
      "How do I get the cool purple text with my major? (probably obvious answer, sorry!)\n",
      "Does the school dye the fountain purple?\n",
      "The ASUW Conspiracy?\n",
      "With my second round of midterm next week, I decided to flip a coin for whether I live or die today with the help of HFS sushi.\n",
      "Graphic design students needed\n",
      "It‚Äôs a long shot but I lost my lanyard somewhere between Padelford hall and Denny hall.\n",
      "Looking for a lost hydroflask...\n",
      "No sushi\n",
      "Anyone else struggling with quarantine?\n",
      "UWashington vs. UC Davis\n",
      "How Do You Deal With Eye Strain?\n",
      "Cuffing season applications are out\n",
      "‚ÄúIt‚Äôs not goodbye. It‚Äôs see you later!‚Äù RIP The 8\n",
      "[Update] Bike stolen off Roosevelt St.\n",
      "Fake Uber by the light rail - be careful\n",
      "Tips on fighting post-exam depression\n",
      "Sleep Routine Post from the Asian Mental Health Alliance @UW on Building a Consistent One!!\n",
      "Washington Cases Have Dropped Off Since July 5th...and New York recorded 0 deaths for first time since march 11.\n",
      "Class vs. Club, Advice?\n",
      "Lost Lamy Fountain Pen in MGH 082\n",
      "To the talented pianist just playing at the HUB this afternoon\n",
      "Why is the CSE building lit up today?\n",
      "Bus annoyances\n",
      "LinkedIn Learning for UW Staff, Students, and Alumni\n",
      "PSA: That guy with a knife was out again today in front of the petco on 45th (around 9:30pm)\n",
      "Does UW needs standardized anti-cheating policies?\n",
      "Looking for Rockers\n",
      "This shit also needs to stop\n",
      "WARNING: pETER j VINCI IS BACK IN U DISTRICT!\n",
      "Stolen Tent and Paddle Board\n",
      "Lounge TV remotes on McCarty?\n",
      "The apologizing masturbator strikes again\n",
      "Reminder: next week is finals, need bluebooks/scantrons?\n",
      "Moving from Mercer to Stevens Court--did I make a mistake?\n",
      "Anybody planing to go to TI6 at the Key lawn this Saturday? I'm looking to get more in touch with the UW people and dota could be a place to start\n",
      "How hard is it to make the computer science program from pre-science?\n",
      "Important! Please read\n",
      "Calculator for MATH 126\n",
      "PSA to ComicCon (ECCC) goers buying Gundams or Pops\n",
      "Anyone wanna jam in the new sound lab in Maple Hall?\n",
      "Lost Class Ring - UW Bookstore\n",
      "Anyone in Music 162? Seeking Help!\n",
      "Where's the best place to nap on campus?\n",
      "Interview at UW on Tuesday, place to crash on Monday night?\n",
      "Difficulty at UW?\n",
      "Lost Class Ring - UW Bookstore\n",
      "Some serious music in the making.\n"
     ]
    }
   ],
   "source": [
    "all2 = reddit.subreddit(\"udub\")\n",
    "for i in all2.search(\"blue\", limit=100):\n",
    "    print (i.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a dataframe from list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dicts_to_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer your own question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What did you learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer this question for today's lecture participation on Canvas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
